<!doctype html>
<html lang="en">
  <head>
    <!-- Required meta tags -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <!-- Bootstrap CSS -->
    <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css" integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">

    <title>1</title>
    <style>
      
      
      body {
        color: #FEFEFE;
        background-color: #0c0d10;    
      }
  @font-face { font-family: "gohu"; src: url("gohu.woff") format('woff'); }
         pre { font-family: "gohu", "Lucida Console", monospace, Monaco; font-size: 15px; line-height: 1.5;}
           a { color: #93ffd7; text-decoration: none; }
           w { color: white;   }
           e { color: #93ffd7; } /* green  */
           k { color: #ff93f1; } /* pink   */
           l { color: #f1ff93; } /* yellow */
           o { color: #93f1ff; } /* blue   */
           r { color: #fa4d57; } /* red    */
  </style>
  <link rel="shortcut icon" type="image/png" href="/favicon/favicon.ico" >
  </head>
  <body>
    <center>
<div style="display: inline-block; text-align: left;">
    <pre style="color: white;">




<a href="/blog.html"><~[Back]</a>

         ／l、      MEOW!
        （ﾟ､ ｡ ７  /
          l、ﾞ~ヽ
          じしf_,)ノ
                  
    My Recon Notes For JHaddix Methodology V4 <a href="/blogs/other/lilith_rec_notes.txt" target="_blank" download>[DOWNLOAD IN TXT FORMAT]</a>

    [ASN]───────────┐                 ┌───────[Root Domain]
                    |────[Recon]──{[TARGET]}
    [Acquisition]───|
                    |
    [Linked]────────|────[Whois]
                    |
        [SubDom]────┘
    <p style="font-size: 25px; color: #fa4d57; font-family:'Lucida Sans', 'Lucida Sans Regular', 'Lucida Grande', 'Lucida Sans Unicode', Geneva, Verdana, sans-serif;">FINDING SEED DOMAIN</p>
        * <a href="https://www.crunchbase.com/" target="_blank">https://crunchbase.com</a> -> find related acquasitions of the company
        (ASN Finding) -> search for company name and asn numbers (doesnt tarcks cloud infra. spaces)
            * <a href="https://bgp.he.net" target="_blank">https://bgp.he.net</a>
            * asnlookup.py(yassineaboukir)
            * metabigor(j3ssiejjj) -> [echo 'tesla' | metabigor net --org -v]
            * asnrecon
            (ASN Enum) -> For discovering more seed domains and return root domains
            * amass(Jeff Foley) -> [amass intel -asn 46489]  
        (Reverse whois)
            * <a href="https://www.whoxy.com" target="_blank">https://www.whoxy.com</a> -> who has owned the company in the past 
            * DOMLink.py(Vincent Yiu) -> recursively query whoxy whois api
        (Ad/Analytics Relationship)
            * <a href="https://builtwith.com/" target="_blank">https://builtwith.com/</a> -> gives technology profile and relations profile   
        (Google-Fu)
            * eg: "2019 Twitch INteractive, Inc." inurl:twitch
        (Shodan)
            * <a href="https://www.shodan.io/search?query=twitch.tv" target="_blank">https://www.shodan.io/search?query=twitch.tv</a> -> spiders infrastructure on the internet
    
      
    <p style="font-size: 25px; color: #fa4d57; font-family:'Lucida Sans', 'Lucida Sans Regular', 'Lucida Grande', 'Lucida Sans Unicode', Geneva, Verdana, sans-serif;">SUBDOMAIN ENUMERATION</p>
          [subdomain enum]
              |-[linked and js discovery]
              |-[subdomain scraping]
              |-[subdomain bruitforce]
              |- ++
      
          (Linked and Js discovery)
              * Burp Suite Pro -> hybrid technique to find both root/seed and subdomain
                  + visit a seed/root and spider all the linked html and js
                  + turn off passive scanning
                  + set forms auto to submit
                  + set scope to advance control and use "keyword" of target
                  + browse the site, then spider all hosts
              * gospider(j3ssiejjj) -> [gospider -s https://www.twitch.tv] 
              * hakrawler(hakluke)
              * subdomainizer(Neeraj Edwards) -> analyzing js and find out subdomains
                  + find cloud services referenced in js files
                  + use shannon entrophy formula to find sensitive items in js files such as api keys
              * subscraper(Cillian Collins) -> just scrapes js files and finds subdomains
      
          (Subdomain Scraping) -> find more subdomains
              (Google) { - is used to exclude and narrow down the results}
                  + site:twitch.tv -www.twitch.tv
                  + site:twitch.tv -www.twitch.tv -watch.twitch.tv
                  + site:twitch.tv -www.twitch.tv -watch.twitch.tv -dev.twitch.tv
              * amass -> [amass -d twitch.tv]
                  + amass correlates the scraped domain to ASN and list where they came forms
                  + this helps to know the technology they are using
              * subfinder(projectdiscovery.io) -> [subfinder -d twitch.tv -v]
              * github-subdomains.py(Gwendal Le) -> scrapes github repos and parse into list of subdomains
              * shosubgo(inc0gbyt3) -> shodan scraper to find subdomain using {needs api key}
              * (Cloud Ranges) -> technique to monitor whole cloud range for SSL sites and parse cert. to match target
                  + eg: [curl 'https://tls.bufferover.run/dns?q=.twitch.tv' 2>/dev/null | jq .Results]
                  + Sam Erb defcon talk on how to set up such service
      
          (Subdomain Bruitforce) -> checking for live subdomains by resolving them
              * amass -> [amass enum -bruit -d twitch.tv -src] | [amass enum -bruit -d twitch.tv -rf resolvers.txt -w wordlist.list]
              * shuffledns(projectdiscovery.io) -> [shuffledns -d twitch.tv -w list.txt -r resolvers.txt]
              (wordlist)
                  * Tailered wordlist
                      + make wordlist in fly
                      + TomNomNom tool for making Tailered wordlist {who, what, where when, wordlist talk}
                  * Massive wordlist
                      + use all in one massive wordlist
                      + all.txt by JHaddix
                      + <a href="https://github.com/assetnote/commonspeak2" target="_blank">https://github.com/assetnote/commonspeak2</a>
              (Alteration Scanning) -> pattern of bruit forcing when a common sequence
                  * eg: dev.company.com | dev1.company.com | dev2.company.com | dev-1.company.com | Dev.2.company.com
      
        
    <p style="font-size: 25px; color: #fa4d57; font-family:'Lucida Sans', 'Lucida Sans Regular', 'Lucida Grande', 'Lucida Sans Unicode', Geneva, Verdana, sans-serif;">OTHERS</p>
          (port scan)
              * masscan(Robert Graham) -> Used for scanning open ports {only for ip and not domain and much faster than nmap}
                                          [masscan -p1-65535 -iL $ipfile --max-rate 1800 -oG $output.log]
                  + syntax guide: <a href="https://danielmiessler.com/study/masscan" target="_blank">https://danielmiessler.com/study/masscan</a>
              * dnmasscan(rastating)   -> Wrapper around masscan to scan domains
                                          [dnmasscan example.txt dns.log -oG scan.log] 
                                          {example.txt contains dns and the ip will be stored in dns.log for further scanning}
          (service scan)
              * brutespray(x90skysn3k) -> scans for default remote admin protocols after port scan
          (github dorking) 
              * Jhaddix bash script for github dork wrapper
              * github-search(Gwendal Le)
              * th3g3ntelman's full module on github sensitive data exposure
          (Screenshotting)
              * Aquatone
              * HTTPscreenshot
              * Eyewitness (for both http and https)
      
      
    <p style="font-size: 25px; color: #fa4d57; font-family:'Lucida Sans', 'Lucida Sans Regular', 'Lucida Grande', 'Lucida Sans Unicode', Geneva, Verdana, sans-serif;">SUBDOMAIN TAKEOVER</p>
              + occurs when a sub is pointing to a service which is removed or deleted.
              + you can setup a page in similar service that was being used and point to that sub.
          * can-i-take-over-xyz(EdOverflow) -> github repo on how to claim subs for different services
          * subover(Ic3man/projectdiscovery.io)
          * nuclei(projectdiscovery.io) -> large scale tool
      
      
    <p style="font-size: 25px; color: #fa4d57; font-family:'Lucida Sans', 'Lucida Sans Regular', 'Lucida Grande', 'Lucida Sans Unicode', Geneva, Verdana, sans-serif;">AUTOMATION++</p>
          * Interlace(Codingo) -> help glue up together these recon tools {hakluke's guide on it}
              + CIDR input
              + Glob input
              + threading
              + proxying
              + queue command
              + etc..
<img src="https://c.tenor.com/sAvoFCX3GucAAAAj/kawaii-dancing.gif">
    </pre>
    </div>
    </center>

    <!-- Optional JavaScript -->
    <!-- jQuery first, then Popper.js, then Bootstrap JS -->
    <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js" integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN" crossorigin="anonymous"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js" integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q" crossorigin="anonymous"></script>
    <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js" integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl" crossorigin="anonymous"></script>
  </body>
</html>
